{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoztEBBCcCz3"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "!git clone https://github.com/alocin98/terrain-gan-public.git\n",
        "%cd terrain-gan-public/code\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data tools\n",
        "%run datatools.py\n",
        "%run models/gan.py\n",
        "%run reporter.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxQs_t96caPW"
      },
      "outputs": [],
      "source": [
        "# Load Tensorboard\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Terrain\\ GAN/logs/detailed-inspection-128px-adapt-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAm1oYItfDXz"
      },
      "outputs": [],
      "source": [
        "# DCGAN\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def buildDCGAN(reporter, title, latent_dim, batch_size, disc_train_ratio):\n",
        "    gan = GAN(reporter, title, latent_dim, disc_train_ratio)\n",
        "    generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "        name=\"generator\",\n",
        "        )\n",
        "    discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128, 128,1)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "        name=\"discriminator\",\n",
        "        )\n",
        "    gan.generator = generator\n",
        "    gan.discriminator = discriminator\n",
        "    return gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n5ygKhVfF6p"
      },
      "outputs": [],
      "source": [
        "# Deeper DCGAN\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def buildFCCGAN(reporter, title, latent_dim, batch_size, disc_train_ratio):\n",
        "    gan = GAN(reporter, title, latent_dim, disc_train_ratio)\n",
        "    generator = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(latent_dim,)),\n",
        "            layers.Dense(2 * 2 * 128),\n",
        "            layers.Dense(4 * 4 * 128),\n",
        "            layers.Dense(8 * 8 * 128),\n",
        "            layers.Reshape((8, 8, 128)),\n",
        "            layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "        ],\n",
        "        name=\"generator\",\n",
        "        )\n",
        "    discriminator = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(128, 128,1)),\n",
        "            layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Flatten(),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Dense(8 * 8 * 128),\n",
        "            layers.Dense(4 * 4 * 128),\n",
        "            layers.Dense(2 * 2 * 128),\n",
        "            layers.Dense(1, activation=\"sigmoid\"),\n",
        "        ],\n",
        "        name=\"discriminator\",\n",
        "        )\n",
        "    gan.generator = generator\n",
        "    gan.discriminator = discriminator\n",
        "    return gan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plain GAN\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def buildGAN(reporter, title, latent_dim, batch_size):\n",
        "    gan = GAN(reporter, title, latent_dim)\n",
        "    generator = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(latent_dim,)),\n",
        "            layers.Dense(2 * 2 * 128),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.BatchNormalization(momentum=0.8),\n",
        "            layers.Dense(4 * 4 * 128),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.BatchNormalization(momentum=0.8),\n",
        "            layers.Dense(8 * 8 * 128),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.BatchNormalization(momentum=0.8),\n",
        "            layers.Dense(128 * 128 * 1, activation='tanh'),\n",
        "            layers.Reshape((128, 128, 1))\n",
        "        ],\n",
        "        name=\"generator\",\n",
        "        )\n",
        "    discriminator = keras.Sequential(\n",
        "        [\n",
        "            layers.Flatten(input_shape=(128, 128,1)),\n",
        "            layers.Dense(512),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Dense(256),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ],\n",
        "        name=\"discriminator\",\n",
        "        )\n",
        "    gan.generator = generator\n",
        "    gan.discriminator = discriminator\n",
        "    return gan"
      ],
      "metadata": {
        "id": "gk6mhgtcQ-jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4xzIXf-8G5x"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "\n",
        "from os import listdir\n",
        "%matplotlib inline\n",
        "\n",
        "logDir = '/content/drive/MyDrive/Terrain GAN/logs/detailed-inspection-128px/'\n",
        "model_save_dir = '/content/drive/MyDrive/Terrain GAN/models/final/'\n",
        "\n",
        "\n",
        "dcgan = buildDCGAN(reporter=TensorBoardReporter(logdir=logDir, print_images=100, checkpoint_filepath=model_save_dir), batch_size=4, title='DCGAN', latent_dim=128, disc_train_ratio=1)\n",
        "fccgan = buildFCCGAN(reporter=TensorBoardReporter(logdir=logDir, print_images=100, checkpoint_filepath=model_save_dir),batch_size=4, title='FCCGAN', latent_dim=128, disc_train_ratio=1)\n",
        "gan = buildGAN(reporter=TensorBoardReporter(logdir=logDir, print_images=100, checkpoint_filepath=model_save_dir),batch_size=4, title='GAN', latent_dim=128)\n",
        "\n",
        "def already_tested(name):\n",
        "  return False\n",
        "  try:\n",
        "    names = listdir(logDir)\n",
        "    return any(name in string for string in names)\n",
        "  except FileNotFoundError:\n",
        "    return False\n",
        "\n",
        "\n",
        "#fccgan-adadelta-0.001-4-meansquarederror-meansquarederror\n",
        "#dcgan-adam-0.0001-4-meansquarederror-binarycrossentropy\n",
        "#gan-adam-0.001-4-binarycrossentropy-binarycrossentropy\n",
        "\n",
        "adgard = tf.keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    name=\"Adagrad\"\n",
        ")\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
        ")\n",
        "\n",
        "adadelta = tf.keras.optimizers.Adadelta(\n",
        "    learning_rate=0.0001, rho=0.95, epsilon=1e-07, name=\"Adadelta\"\n",
        ")\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\", clipnorm=1.0\n",
        ")\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "optimizers = [(adam, 'adam-0.0001'), (adgard, 'adgard-0.0001'), (adamax, 'adadelta-0.001'), (sgd, 'sgd-0.01')]\n",
        "epochs = 100\n",
        "\n",
        "loss_fns = [(keras.losses.BinaryCrossentropy(), 'binarycrossentropy'), (keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\"), 'meansquarederror')]\n",
        "\n",
        "def getLogNameByArguments(args):\n",
        "  return args.get('optimizer') +'-'+ args.get('loss_fn')\n",
        "\n",
        "for optimizer in optimizers:\n",
        "  for loss_fn in loss_fns:\n",
        "      data = getData('../data/alps_hgt/', scale=2, resolution=128, step=0.1)\n",
        "      args = dict(data=data[0:200],optimizer=optimizer[0],batch_size=\"14\",epochs=epochs,loss_fn=loss_fn[0])\n",
        "      names = dict(data=data[0:200],optimizer=optimizer[1],epochs=epochs,loss_fn=loss_fn[1])\n",
        "      logname = 'plaingan-' + getLogNameByArguments(names) + '-scale-1-200-samples-step-1-100-epochs'\n",
        "      if not already_tested(logname):\n",
        "        print(\"training: \" + logname)\n",
        "        gan.train(**args, logname=logname)\n",
        "        tf.keras.backend.clear_session()\n",
        "      else:\n",
        "        print(logname + \" already tested\")\n",
        "      logname = 'fccgan-' + getLogNameByArguments(names) + '-scale-' + str(scale) + '-500-samples-step-' + str(step/10) + '-100-epochs-FINAL'\n",
        "      if not already_tested(logname):\n",
        "        print(\"training: \" + logname)\n",
        "        fccgan.train(**args, logname=logname)\n",
        "        tf.keras.backend.clear_session()\n",
        "      else:\n",
        "        print(logname + \" already tested\")\n",
        "        logname = 'plaingan-' + getLogNameByArguments(names) + '-scale-' + str(i)\n",
        "      if not already_tested(logname):\n",
        "        print(\"training: \" + logname)\n",
        "        gan.train(**args, logname=logname)\n",
        "        tf.keras.backend.clear_session()\n",
        "      else:\n",
        "        print(logname + \" already tested\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "inspection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}